{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmCa4jqF3Bs1",
        "outputId": "141acccd-869c-45ac-c0c9-0a8311761de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 29 09:48:34 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.cu\n",
        "// ==============================\n",
        "// 0) Подключаем библиотеки\n",
        "// ==============================\n",
        "\n",
        "#include <cuda_runtime.h>              // CUDA: память + запуск kernel\n",
        "#include <iostream>                    // cout/cerr\n",
        "#include <vector>                      // std::vector\n",
        "#include <random>                      // генерация случайных чисел\n",
        "#include <chrono>                      // тайминг CPU\n",
        "#include <climits>                     // INT_MAX\n",
        "#include <algorithm>                   // std::swap\n",
        "\n",
        "// ==============================\n",
        "// 0.1) Макрос проверки CUDA-ошибок\n",
        "// ==============================\n",
        "\n",
        "// CHECK(...) — если CUDA-вызов провалился, выводим ошибку и выходим\n",
        "#define CHECK(x) do { \\\n",
        "  cudaError_t err = (x); \\\n",
        "  if (err != cudaSuccess) { \\\n",
        "    std::cerr << \"CUDA error: \" << cudaGetErrorString(err) \\\n",
        "              << \" at \" << __FILE__ << \":\" << __LINE__ << \"\\n\"; \\\n",
        "    std::exit(1); \\\n",
        "  } \\\n",
        "} while(0)\n",
        "\n",
        "\n",
        "// ============================================================\n",
        "// 1) CPU BLOCK: последовательные сортировки + тайминг\n",
        "// ============================================================\n",
        "\n",
        "// ------------------------------\n",
        "// 1.1) CPU MergeSort\n",
        "// ------------------------------\n",
        "\n",
        "// Сливаем две отсортированные части: [l..m) и [m..r)\n",
        "static void cpu_merge(std::vector<int>& a, int l, int m, int r, std::vector<int>& tmp) {\n",
        "  int i = l;                              // индекс в левой части\n",
        "  int j = m;                              // индекс в правой части\n",
        "  int k = l;                              // индекс записи во временный массив\n",
        "\n",
        "  while (i < m && j < r) {                // пока обе части не закончились\n",
        "    tmp[k++] = (a[i] <= a[j]) ? a[i++] : a[j++]; // берём меньший элемент\n",
        "  }\n",
        "\n",
        "  while (i < m) tmp[k++] = a[i++];        // дописываем остаток левой части\n",
        "  while (j < r) tmp[k++] = a[j++];        // дописываем остаток правой части\n",
        "\n",
        "  for (int t = l; t < r; t++) a[t] = tmp[t]; // копируем обратно в исходный массив\n",
        "}\n",
        "\n",
        "// Рекурсивная часть MergeSort\n",
        "static void cpu_merge_sort_rec(std::vector<int>& a, int l, int r, std::vector<int>& tmp) {\n",
        "  if (r - l <= 1) return;                 // 0 или 1 элемент уже отсортирован\n",
        "\n",
        "  int m = l + (r - l) / 2;                // середина диапазона\n",
        "  cpu_merge_sort_rec(a, l, m, tmp);        // сортируем левую часть\n",
        "  cpu_merge_sort_rec(a, m, r, tmp);        // сортируем правую часть\n",
        "  cpu_merge(a, l, m, r, tmp);              // сливаем\n",
        "}\n",
        "\n",
        "// Внешняя функция CPU MergeSort\n",
        "static void cpu_merge_sort(std::vector<int>& a) {\n",
        "  std::vector<int> tmp(a.size());         // временный массив\n",
        "  cpu_merge_sort_rec(a, 0, (int)a.size(), tmp); // запускаем рекурсию\n",
        "}\n",
        "\n",
        "// ------------------------------\n",
        "// 1.2) CPU QuickSort\n",
        "// ------------------------------\n",
        "\n",
        "// Разделение массива по pivot (опорному элементу)\n",
        "static int cpu_partition(std::vector<int>& a, int l, int r) {\n",
        "  int pivot = a[r - 1];                   // pivot = последний элемент\n",
        "  int i = l;                              // индекс позиции для меньших элементов\n",
        "\n",
        "  for (int j = l; j < r - 1; j++) {       // пробегаем все элементы, кроме pivot\n",
        "    if (a[j] <= pivot) {                  // если элемент <= pivot\n",
        "      std::swap(a[i], a[j]);              // меняем местами\n",
        "      i++;                                // увеличиваем границу\n",
        "    }\n",
        "  }\n",
        "\n",
        "  std::swap(a[i], a[r - 1]);              // ставим pivot на правильное место\n",
        "  return i;                               // возвращаем индекс pivot\n",
        "}\n",
        "\n",
        "// Рекурсивный CPU QuickSort\n",
        "static void cpu_quick_sort_rec(std::vector<int>& a, int l, int r) {\n",
        "  if (r - l <= 1) return;                 // база рекурсии\n",
        "\n",
        "  int p = cpu_partition(a, l, r);         // делим массив на части\n",
        "  cpu_quick_sort_rec(a, l, p);            // сортируем левую часть\n",
        "  cpu_quick_sort_rec(a, p + 1, r);        // сортируем правую часть\n",
        "}\n",
        "\n",
        "// Внешняя функция CPU QuickSort\n",
        "static void cpu_quick_sort(std::vector<int>& a) {\n",
        "  cpu_quick_sort_rec(a, 0, (int)a.size()); // запуск\n",
        "}\n",
        "\n",
        "// ------------------------------\n",
        "// 1.3) CPU HeapSort\n",
        "// ------------------------------\n",
        "\n",
        "// Функция \"просеивания\" вниз для кучи\n",
        "static void cpu_heapify(std::vector<int>& a, int n, int i) {\n",
        "  int largest = i;                        // считаем i самым большим\n",
        "  int L = 2 * i + 1;                      // левый ребёнок\n",
        "  int R = 2 * i + 2;                      // правый ребёнок\n",
        "\n",
        "  if (L < n && a[L] > a[largest]) largest = L; // выбираем большего\n",
        "  if (R < n && a[R] > a[largest]) largest = R; // выбираем большего\n",
        "\n",
        "  if (largest != i) {                     // если ребёнок больше\n",
        "    std::swap(a[i], a[largest]);          // меняем\n",
        "    cpu_heapify(a, n, largest);           // продолжаем вниз\n",
        "  }\n",
        "}\n",
        "\n",
        "// CPU HeapSort\n",
        "static void cpu_heap_sort(std::vector<int>& a) {\n",
        "  int n = (int)a.size();                  // размер массива\n",
        "\n",
        "  for (int i = n / 2 - 1; i >= 0; i--) {  // строим кучу снизу вверх\n",
        "    cpu_heapify(a, n, i);                 // heapify\n",
        "  }\n",
        "\n",
        "  for (int i = n - 1; i > 0; i--) {       // извлекаем максимум\n",
        "    std::swap(a[0], a[i]);                // перемещаем максимум в конец\n",
        "    cpu_heapify(a, i, 0);                 // восстанавливаем кучу\n",
        "  }\n",
        "}\n",
        "\n",
        "// ------------------------------\n",
        "// 1.4) Функция тайминга CPU (мс)\n",
        "// ------------------------------\n",
        "static double cpu_ms(std::chrono::high_resolution_clock::time_point a,\n",
        "                     std::chrono::high_resolution_clock::time_point b) {\n",
        "  return std::chrono::duration<double, std::milli>(b - a).count(); // ms\n",
        "}\n",
        "\n",
        "\n",
        "// ============================================================\n",
        "// 2) GPU BLOCK: сортировка чанков + простое merge + тайминг\n",
        "// ============================================================\n",
        "\n",
        "// ------------------------------\n",
        "// 2.1) GPU MergeSort: bitonic сортировка чанка (параллельно)\n",
        "// ------------------------------\n",
        "\n",
        "// CHUNK — размер чанка (и threads per block)\n",
        "// каждый блок сортирует один чанк\n",
        "template<int CHUNK>\n",
        "__global__ void bitonicSortChunks(int* d, int n) {\n",
        "  __shared__ int s[CHUNK];                // shared memory для чанка\n",
        "\n",
        "  int chunkStart = blockIdx.x * CHUNK;    // начало чанка\n",
        "  int tid = threadIdx.x;                  // номер потока в блоке\n",
        "  int idx = chunkStart + tid;             // глобальный индекс\n",
        "\n",
        "  s[tid] = (idx < n) ? d[idx] : INT_MAX;  // грузим элемент или INT_MAX\n",
        "  __syncthreads();                        // ждём все потоки\n",
        "\n",
        "  for (int k = 2; k <= CHUNK; k <<= 1) {  // размер \"подпоследовательности\"\n",
        "    for (int j = k >> 1; j > 0; j >>= 1) {// шаг сравнения\n",
        "      int ixj = tid ^ j;                  // \"пара\" для сравнения\n",
        "      if (ixj > tid) {                    // чтобы не сравнивать дважды\n",
        "        bool up = ((tid & k) == 0);       // направление сортировки\n",
        "        int a = s[tid];                   // значение потока tid\n",
        "        int b = s[ixj];                   // значение потока ixj\n",
        "        if ((up && a > b) || (!up && a < b)) { // условие swap\n",
        "          s[tid] = b;                     // меняем\n",
        "          s[ixj] = a;                     // меняем\n",
        "        }\n",
        "      }\n",
        "      __syncthreads();                    // синхронизация\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if (idx < n) d[idx] = s[tid];           // записываем обратно\n",
        "}\n",
        "\n",
        "// ------------------------------\n",
        "// 2.2) GPU QuickSort: сортировка чанка одним потоком\n",
        "// ------------------------------\n",
        "\n",
        "// простая device-функция quicksort (итеративно) для массива в shared\n",
        "__device__ void device_quick_sort(int* a, int n) {\n",
        "  int L[64], R[64];                       // стек диапазонов\n",
        "  int top = 0;                            // вершина стека\n",
        "  L[top] = 0; R[top] = n - 1; top++;      // кладём первый диапазон\n",
        "\n",
        "  while (top > 0) {                       // пока стек не пуст\n",
        "    top--;                                // берём последний диапазон\n",
        "    int l = L[top], r = R[top];           // границы\n",
        "    if (l >= r) continue;                 // если 0/1 элемент — пропуск\n",
        "\n",
        "    int pivot = a[r];                     // pivot\n",
        "    int i = l;                            // индекс разделения\n",
        "    for (int j = l; j < r; j++) {         // проход по диапазону\n",
        "      if (a[j] <= pivot) {                // если <= pivot\n",
        "        int t = a[i]; a[i] = a[j]; a[j] = t; // swap\n",
        "        i++;                              // сдвиг границы\n",
        "      }\n",
        "    }\n",
        "    { int t = a[i]; a[i] = a[r]; a[r] = t; } // ставим pivot на место\n",
        "\n",
        "    if (i - 1 > l) { L[top] = l; R[top] = i - 1; top++; } // левый диапазон\n",
        "    if (i + 1 < r) { L[top] = i + 1; R[top] = r; top++; } // правый диапазон\n",
        "  }\n",
        "}\n",
        "\n",
        "// kernel: загружаем чанк в shared, поток 0 сортирует, остальные ждут\n",
        "template<int CHUNK>\n",
        "__global__ void quickSortChunks(int* d, int n) {\n",
        "  __shared__ int s[CHUNK];                // shared memory для чанка\n",
        "\n",
        "  int chunkStart = blockIdx.x * CHUNK;    // начало чанка\n",
        "  int tid = threadIdx.x;                  // поток\n",
        "  int idx = chunkStart + tid;             // глобальный индекс\n",
        "\n",
        "  s[tid] = (idx < n) ? d[idx] : INT_MAX;  // грузим в shared\n",
        "  __syncthreads();                        // ждём всех\n",
        "\n",
        "  if (tid == 0) {                         // только один поток сортирует\n",
        "    int len = min(CHUNK, n - chunkStart); // реальная длина чанка\n",
        "    device_quick_sort(s, len);            // сортировка\n",
        "  }\n",
        "  __syncthreads();                        // ждём завершения сортировки\n",
        "\n",
        "  if (idx < n) d[idx] = s[tid];           // записываем обратно\n",
        "}\n",
        "\n",
        "// ------------------------------\n",
        "// 2.3) GPU HeapSort: сортировка чанка одним потоком\n",
        "// ------------------------------\n",
        "\n",
        "// heapify на device\n",
        "__device__ void device_heapify(int* a, int n, int i) {\n",
        "  while (true) {                          // цикл \"вниз\"\n",
        "    int largest = i;                      // предполагаем i самый большой\n",
        "    int L = 2 * i + 1;                    // левый ребёнок\n",
        "    int R = 2 * i + 2;                    // правый ребёнок\n",
        "    if (L < n && a[L] > a[largest]) largest = L; // выбираем большего\n",
        "    if (R < n && a[R] > a[largest]) largest = R; // выбираем большего\n",
        "    if (largest == i) break;              // если i уже на месте — выход\n",
        "    int t = a[i]; a[i] = a[largest]; a[largest] = t; // swap\n",
        "    i = largest;                          // спускаемся вниз\n",
        "  }\n",
        "}\n",
        "\n",
        "// heapsort на device\n",
        "__device__ void device_heap_sort(int* a, int n) {\n",
        "  for (int i = n / 2 - 1; i >= 0; i--) device_heapify(a, n, i); // строим кучу\n",
        "  for (int i = n - 1; i > 0; i--) {     // извлекаем максимум\n",
        "    int t = a[0]; a[0] = a[i]; a[i] = t; // swap\n",
        "    device_heapify(a, i, 0);            // heapify\n",
        "  }\n",
        "}\n",
        "\n",
        "// kernel: поток 0 сортирует чанк heapsort\n",
        "template<int CHUNK>\n",
        "__global__ void heapSortChunks(int* d, int n) {\n",
        "  __shared__ int s[CHUNK];                // shared memory\n",
        "\n",
        "  int chunkStart = blockIdx.x * CHUNK;    // начало чанка\n",
        "  int tid = threadIdx.x;                  // поток\n",
        "  int idx = chunkStart + tid;             // глобальный индекс\n",
        "\n",
        "  s[tid] = (idx < n) ? d[idx] : INT_MAX;  // грузим в shared\n",
        "  __syncthreads();                        // синхронизация\n",
        "\n",
        "  if (tid == 0) {                         // один поток сортирует\n",
        "    int len = min(CHUNK, n - chunkStart); // реальная длина чанка\n",
        "    device_heap_sort(s, len);             // heapsort\n",
        "  }\n",
        "  __syncthreads();                        // ждём завершения сортировки\n",
        "\n",
        "  if (idx < n) d[idx] = s[tid];           // запись обратно\n",
        "}\n",
        "\n",
        "// ------------------------------\n",
        "// 2.4) GPU merge: простое попарное слияние (без merge-path)\n",
        "// ------------------------------\n",
        "\n",
        "__global__ void mergePairsSimple(const int* in, int* out, int n, int run) {\n",
        "  int pairId = blockIdx.x;                       // номер пары сегментов\n",
        "  int left0 = pairId * (2 * run);                // начало пары\n",
        "  if (left0 >= n) return;                        // если вышли за массив — выходим\n",
        "\n",
        "  int mid0   = min(left0 + run, n);              // середина пары\n",
        "  int right0 = min(left0 + 2 * run, n);          // конец пары\n",
        "\n",
        "  const int* A = in + left0;                     // левый отсортированный сегмент\n",
        "  const int* B = in + mid0;                      // правый отсортированный сегмент\n",
        "  int aN = mid0 - left0;                         // длина левого сегмента\n",
        "  int bN = right0 - mid0;                        // длина правого сегмента\n",
        "  int total = aN + bN;                           // общая длина после слияния\n",
        "\n",
        "  int* C = out + left0;                          // куда пишем результат\n",
        "\n",
        "  // каждый поток делает несколько позиций k в результирующем массиве\n",
        "  for (int k = threadIdx.x; k < total; k += blockDim.x) {\n",
        "\n",
        "    // i = сколько элементов берём из A, j = сколько из B, и i + j = k\n",
        "    int iMin = max(0, k - bN);\n",
        "    int iMax = min(k, aN);\n",
        "\n",
        "    // бинарный поиск по i\n",
        "    while (iMin <= iMax) {\n",
        "      int i = (iMin + iMax) >> 1;\n",
        "      int j = k - i;\n",
        "\n",
        "      int aLeft  = (i > 0)  ? A[i - 1] : INT_MIN;\n",
        "      int aRight = (i < aN) ? A[i]     : INT_MAX;\n",
        "      int bLeft  = (j > 0)  ? B[j - 1] : INT_MIN;\n",
        "      int bRight = (j < bN) ? B[j]     : INT_MAX;\n",
        "\n",
        "      // нашли правильное разбиение\n",
        "      if (aLeft <= bRight && bLeft <= aRight) {\n",
        "        C[k] = (aRight <= bRight) ? aRight : bRight;  // элемент на позиции k\n",
        "        break;\n",
        "      }\n",
        "\n",
        "      // сдвигаем бинарный поиск\n",
        "      if (aLeft > bRight) iMax = i - 1;\n",
        "      else                iMin = i + 1;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "// ------------------------------\n",
        "// 2.5) GPU wrapper: sort chunks + merge stages + cudaEvent timing\n",
        "// ------------------------------\n",
        "\n",
        "// режим какой алгоритм сортировки чанков использовать\n",
        "enum GpuMode { GPU_MERGE = 1, GPU_QUICK = 2, GPU_HEAP = 3 };\n",
        "\n",
        "template<int CHUNK>\n",
        "float gpu_sort_chunk_and_merge(int* d, int n, int mode) {\n",
        "  int blocks = (n + CHUNK - 1) / CHUNK;   // количество чанков (блоков)\n",
        "\n",
        "  cudaEvent_t s, e;                       // CUDA события для тайминга\n",
        "  CHECK(cudaEventCreate(&s));             // создаём start event\n",
        "  CHECK(cudaEventCreate(&e));             // создаём end event\n",
        "  CHECK(cudaEventRecord(s));              // старт таймера\n",
        "\n",
        "  // 1) сортировка чанков\n",
        "  if (mode == GPU_MERGE) {\n",
        "    bitonicSortChunks<CHUNK><<<blocks, CHUNK>>>(d, n); // битоник параллельно\n",
        "  } else if (mode == GPU_QUICK) {\n",
        "    quickSortChunks<CHUNK><<<blocks, CHUNK>>>(d, n);   // quick в чанке\n",
        "  } else {\n",
        "    heapSortChunks<CHUNK><<<blocks, CHUNK>>>(d, n);    // heap в чанке\n",
        "  }\n",
        "  CHECK(cudaGetLastError());             // проверяем запуск kernel\n",
        "\n",
        "  // 2) temp-массив для merge\n",
        "  int* temp = nullptr;                   // указатель на временный буфер\n",
        "  CHECK(cudaMalloc(&temp, n * sizeof(int))); // выделяем на GPU\n",
        "\n",
        "  int run = CHUNK;                        // текущая длина отсортированного блока\n",
        "  int* in  = d;                           // откуда читаем\n",
        "  int* out = temp;                        // куда пишем\n",
        "\n",
        "  // 3) поэтапное слияние: CHUNK -> 2CHUNK -> 4CHUNK -> ...\n",
        "  while (run < n) {\n",
        "    int pairs = (n + (2 * run) - 1) / (2 * run); // число пар\n",
        "    mergePairsSimple<<<pairs, 256>>>(in, out, n, run); // простой merge\n",
        "    CHECK(cudaGetLastError());            // проверка kernel\n",
        "    std::swap(in, out);                   // меняем буферы местами\n",
        "    run *= 2;                             // увеличиваем размер блока\n",
        "  }\n",
        "\n",
        "  // если итог оказался в temp — копируем в d\n",
        "  if (in != d) {\n",
        "    CHECK(cudaMemcpy(d, in, n * sizeof(int), cudaMemcpyDeviceToDevice));\n",
        "  }\n",
        "\n",
        "  CHECK(cudaFree(temp));                  // освобождаем temp\n",
        "\n",
        "  CHECK(cudaEventRecord(e));              // стоп таймера\n",
        "  CHECK(cudaEventSynchronize(e));         // ждём завершения всех GPU задач\n",
        "\n",
        "  float ms = 0.0f;                        // время в миллисекундах\n",
        "  CHECK(cudaEventElapsedTime(&ms, s, e)); // считаем время\n",
        "  CHECK(cudaEventDestroy(s));             // удаляем события\n",
        "  CHECK(cudaEventDestroy(e));             // удаляем события\n",
        "\n",
        "  return ms;                              // возвращаем ms\n",
        "}\n",
        "\n",
        "\n",
        "// ============================================================\n",
        "// 3) BENCHMARK BLOCK: сравнение CPU vs GPU\n",
        "// ============================================================\n",
        "\n",
        "int main() {\n",
        "  std::vector<int> sizes = {10000, 100000, 1000000}; // тестовые размеры\n",
        "\n",
        "  std::mt19937 rng(42);                               // генератор\n",
        "  std::uniform_int_distribution<int> dist(0, 1000000);// диапазон\n",
        "\n",
        "  for (int N : sizes) {                               // перебираем размеры\n",
        "    std::vector<int> base(N);                         // исходный массив\n",
        "\n",
        "    for (int i = 0; i < N; i++) base[i] = dist(rng);  // заполняем числами\n",
        "\n",
        "    // ---------- CPU: считаем время каждой сортировки ----------\n",
        "    auto cpuMerge = base;                             // копия для merge\n",
        "    auto t1 = std::chrono::high_resolution_clock::now();// start\n",
        "    cpu_merge_sort(cpuMerge);                         // merge sort\n",
        "    auto t2 = std::chrono::high_resolution_clock::now();// end\n",
        "    double cpuMergeMs = cpu_ms(t1, t2);               // ms\n",
        "\n",
        "    auto cpuQuick = base;                             // копия для quick\n",
        "    t1 = std::chrono::high_resolution_clock::now();   // start\n",
        "    cpu_quick_sort(cpuQuick);                         // quick sort\n",
        "    t2 = std::chrono::high_resolution_clock::now();   // end\n",
        "    double cpuQuickMs = cpu_ms(t1, t2);               // ms\n",
        "\n",
        "    auto cpuHeap = base;                              // копия для heap\n",
        "    t1 = std::chrono::high_resolution_clock::now();   // start\n",
        "    cpu_heap_sort(cpuHeap);                           // heap sort\n",
        "    t2 = std::chrono::high_resolution_clock::now();   // end\n",
        "    double cpuHeapMs = cpu_ms(t1, t2);                // ms\n",
        "\n",
        "    // ---------- GPU: выделяем память один раз ----------\n",
        "    int* d = nullptr;                                 // указатель на GPU массив\n",
        "    CHECK(cudaMalloc(&d, N * sizeof(int)));           // выделяем память\n",
        "\n",
        "    // ---------- GPU MergeSort ----------\n",
        "    auto gpuMerge = base;                             // копия для GPU\n",
        "    CHECK(cudaMemcpy(d, gpuMerge.data(), N*sizeof(int), cudaMemcpyHostToDevice)); // H2D\n",
        "    float gpuMergeMs = gpu_sort_chunk_and_merge<512>(d, N, GPU_MERGE); // запуск\n",
        "    CHECK(cudaMemcpy(gpuMerge.data(), d, N*sizeof(int), cudaMemcpyDeviceToHost)); // D2H\n",
        "    bool okMerge = (gpuMerge == cpuMerge);            // проверка корректности\n",
        "\n",
        "    // ---------- GPU QuickSort ----------\n",
        "    auto gpuQuick = base;                             // копия\n",
        "    CHECK(cudaMemcpy(d, gpuQuick.data(), N*sizeof(int), cudaMemcpyHostToDevice)); // H2D\n",
        "    float gpuQuickMs = gpu_sort_chunk_and_merge<512>(d, N, GPU_QUICK); // запуск\n",
        "    CHECK(cudaMemcpy(gpuQuick.data(), d, N*sizeof(int), cudaMemcpyDeviceToHost)); // D2H\n",
        "    bool okQuick = (gpuQuick == cpuMerge);            // сравниваем с эталоном cpuMerge\n",
        "\n",
        "    // ---------- GPU HeapSort ----------\n",
        "    auto gpuHeap = base;                              // копия\n",
        "    CHECK(cudaMemcpy(d, gpuHeap.data(), N*sizeof(int), cudaMemcpyHostToDevice)); // H2D\n",
        "    float gpuHeapMs = gpu_sort_chunk_and_merge<512>(d, N, GPU_HEAP); // запуск\n",
        "    CHECK(cudaMemcpy(gpuHeap.data(), d, N*sizeof(int), cudaMemcpyDeviceToHost)); // D2H\n",
        "    bool okHeap = (gpuHeap == cpuMerge);              // сравнение с эталоном\n",
        "\n",
        "    CHECK(cudaFree(d));                               // освобождаем GPU память\n",
        "\n",
        "    // ---------- Вывод результатов ----------\n",
        "    std::cout << \"\\n==============================\\n\";   // разделитель\n",
        "    std::cout << \"N = \" << N << \"\\n\";                 // размер\n",
        "    std::cout << \"==============================\\n\";   // разделитель\n",
        "\n",
        "    std::cout << \"CPU MergeSort: \" << cpuMergeMs << \" ms\\n\"; // CPU merge время\n",
        "    std::cout << \"CPU QuickSort: \" << cpuQuickMs << \" ms\\n\"; // CPU quick время\n",
        "    std::cout << \"CPU HeapSort:  \" << cpuHeapMs  << \" ms\\n\"; // CPU heap время\n",
        "\n",
        "    std::cout << \"GPU MergeSort: \" << gpuMergeMs << \" ms | \" << (okMerge ? \"OK\" : \"ERROR\") << \"\\n\"; // GPU merge\n",
        "    std::cout << \"GPU QuickSort: \" << gpuQuickMs << \" ms | \" << (okQuick ? \"OK\" : \"ERROR\") << \"\\n\"; // GPU quick\n",
        "    std::cout << \"GPU HeapSort:  \" << gpuHeapMs  << \" ms | \" << (okHeap  ? \"OK\" : \"ERROR\") << \"\\n\"; // GPU heap\n",
        "\n",
        "    // speedup (если GPU быстрее, будет > 1)\n",
        "    if (gpuMergeMs > 0) std::cout << \"Speedup Merge (CPU/GPU): \" << (cpuMergeMs / gpuMergeMs) << \"x\\n\";\n",
        "    if (gpuQuickMs > 0) std::cout << \"Speedup Quick (CPU/GPU): \" << (cpuQuickMs / gpuQuickMs) << \"x\\n\";\n",
        "    if (gpuHeapMs  > 0) std::cout << \"Speedup Heap  (CPU/GPU): \" << (cpuHeapMs  / gpuHeapMs ) << \"x\\n\";\n",
        "  }\n",
        "\n",
        "  return 0;                                            // конец программы\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvp_XfzM7wSz",
        "outputId": "e2aa59b0-baf0-4615-cfff-f727ff6382f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -std=c++17 -O3 main.cu -o main -gencode arch=compute_75,code=sm_75\n"
      ],
      "metadata": {
        "id": "RxRHl6y076Ef"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXxKPcyh781y",
        "outputId": "bf382bae-097a-4008-e9f5-bb2b0ebfcbf7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "N = 10000\n",
            "==============================\n",
            "CPU MergeSort: 1.10619 ms\n",
            "CPU QuickSort: 0.722627 ms\n",
            "CPU HeapSort:  0.944553 ms\n",
            "GPU MergeSort: 0.57328 ms | OK\n",
            "GPU QuickSort: 1.0711 ms | OK\n",
            "GPU HeapSort:  1.61709 ms | OK\n",
            "Speedup Merge (CPU/GPU): 1.92958x\n",
            "Speedup Quick (CPU/GPU): 0.674656x\n",
            "Speedup Heap  (CPU/GPU): 0.584107x\n",
            "\n",
            "==============================\n",
            "N = 100000\n",
            "==============================\n",
            "CPU MergeSort: 10.9185 ms\n",
            "CPU QuickSort: 7.692 ms\n",
            "CPU HeapSort:  11.2952 ms\n",
            "GPU MergeSort: 4.50768 ms | OK\n",
            "GPU QuickSort: 6.23587 ms | OK\n",
            "GPU HeapSort:  8.07011 ms | OK\n",
            "Speedup Merge (CPU/GPU): 2.4222x\n",
            "Speedup Quick (CPU/GPU): 1.23351x\n",
            "Speedup Heap  (CPU/GPU): 1.39964x\n",
            "\n",
            "==============================\n",
            "N = 1000000\n",
            "==============================\n",
            "CPU MergeSort: 134.164 ms\n",
            "CPU QuickSort: 95.1539 ms\n",
            "CPU HeapSort:  152.514 ms\n",
            "GPU MergeSort: 57.7844 ms | OK\n",
            "GPU QuickSort: 67.5834 ms | OK\n",
            "GPU HeapSort:  74.0383 ms | OK\n",
            "Speedup Merge (CPU/GPU): 2.32181x\n",
            "Speedup Quick (CPU/GPU): 1.40795x\n",
            "Speedup Heap  (CPU/GPU): 2.05993x\n"
          ]
        }
      ]
    }
  ]
}