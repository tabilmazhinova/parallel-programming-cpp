# Practice 3

## Состав проекта
- task1.cpp — 
    1. Реализовать параллельную сортировку слиянием на CUDA:Разделите массив на блоки, каждый из которых будет обрабатываться одним блоком потоков. Сортируйте блоки параллельно и сливайте их по парам.
    2. Реализовать параллельную быструю сортировку на CUDA: Используйте параллельные потоки для деления массива по опорному
    элементу. В каждом потоке выполняется быстрая сортировка на своей части массива.
    3. Реализовать параллельную пирамидальную сортировку на CUDA: Постройте кучу и выполняйте извлечение элементов параллельно, где это возможно.
    4. Сравнение производительности: Реализуйте последовательные версии этих алгоритмов на CPU. Измерьте время выполнения каждой сортировки на CPU и на GPU для массивов разного размера (например, 10,000, 100,000 и 1,000,000 элементов).
    Сравните производительность и сделайте выводы.

## Сборка и запуск 

### Task (CPU + GPU)
!nvcc -std=c++17 -O3 main.cu -o main -gencode arch=compute_75,code=sm_75
!./main

## Notes (macOS)
В macOS невозможна поэтому реализация была сделана в гугл колабе.

## Output
    Скрин вывода консоли: output.png
    Блок-схема: bsh-task1.png

## Контрольные вопросы

### 1. В чём различие между последовательной и параллельной реализацией сортировки слиянием?
В последовательной реализации сортировка выполняется в одном потоке: массив делится на части и обрабатывается по очереди.  
В параллельной реализации разные части массива сортируются одновременно в нескольких потоках или блоках, что ускоряет работу на больших объёмах данных.

### 2. Как распределение потоков и блоков влияет на производительность на CUDA?
Распределение потоков и блоков определяет, насколько эффективно используется GPU.  
Если потоков мало — GPU простаивает, если слишком много — появляются лишние накладные расходы.  
Правильное распределение позволяет добиться максимальной производительности.

### 3. Какие сложности возникают при реализации быстрой сортировки на GPU?
Быстрая сортировка имеет неравномерное разбиение массива и много ветвлений.  
Из-за этого сложно равномерно распределить работу между потоками, и эффективность на GPU снижается.

### 4. В каких случаях параллельная реализация сортировки на GPU может быть менее эффективной, чем на CPU?
GPU-сортировка может быть медленнее, если массив небольшой,  
если много времени уходит на передачу данных между CPU и GPU,  
или если алгоритм плохо подходит для параллельного выполнения.

### 5. Почему важно правильно выбирать размер блоков и потоков в CUDA?
Размер блоков и потоков влияет на загрузку вычислительных ресурсов GPU.  
Неправильный выбор может привести к снижению производительности даже при корректном алгоритме.

### 6. Как использование разделяемой памяти может повлиять на производительность сортировки?
Разделяемая память работает быстрее, чем глобальная память GPU.  
Использование её при сортировке уменьшает задержки доступа к данным и ускоряет выполнение программы.

### 7. Что означает принцип «разделяй и властвуй» в контексте алгоритмов сортировки?
Принцип «разделяй и властвуй» заключается в разбиении задачи на несколько меньших подзадач.  
Каждая часть решается отдельно, после чего результаты объединяются в общий отсортированный массив.
